{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet_classification_Kaggle.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCyyJkh8Ecu0Y4fq8eE3wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adi8885/RecurrentNets/blob/master/Tweet_classification_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3MnkIpc8xzg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "93cea793-085e-4684-e50b-0234dbfe73a4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import classification_report , f1_score , accuracy_score , confusion_matrix\n",
        "#import skopt\n",
        "import time\n",
        "from transformers import BertModel , BertTokenizer , BertForSequenceClassification\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import logging\n",
        "\n",
        "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bmBk7kU9VR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f8d94897-8fc4-488a-cf28-783872abd4e1"
      },
      "source": [
        "data = pd.read_csv('train.csv' , low_memory = False)\n",
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceTgy_Hy9brA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0f78bcce-d358-4a56-893e-ad36196ca4e0"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "keyword       61\n",
              "location    2533\n",
              "text           0\n",
              "target         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chv0phWy9hJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "aedb8a6a-1c2c-4a29-e008-edad5d73a03d"
      },
      "source": [
        "data.groupby('target')['id'].count()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    4342\n",
              "1    3271\n",
              "Name: id, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMzNfhjt9uBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[['text','target']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd7YdNz_-BuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['word_count'] = data['text'].apply(lambda x: len(str(x).split(\" \")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYznUhYA-odr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "027e090f-caaa-474d-f956-46bf28642011"
      },
      "source": [
        "data['word_count'].describe(percentiles = [0.5 ,0.75 , 0.9 , 0.95 , 0.98 , 0.99])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    7613.000000\n",
              "mean       14.928937\n",
              "std         5.782770\n",
              "min         1.000000\n",
              "50%        15.000000\n",
              "75%        19.000000\n",
              "90%        23.000000\n",
              "95%        24.000000\n",
              "98%        26.000000\n",
              "99%        27.000000\n",
              "max        54.000000\n",
              "Name: word_count, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1XDaQQj-wiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.text.str.lower()\n",
        "Y = data.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yDi9HkX_Yo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "556d2c69-1800-498c-94db-fc54aca55aee"
      },
      "source": [
        "word_dict = {}\n",
        "word_ctr = 0\n",
        "for i in X.index:\n",
        "  sentence = X.loc[i].split(' ')\n",
        "  for j in sentence:\n",
        "    if word_dict.get(j,0) == 0 :\n",
        "      word_dict[word_ctr] = j\n",
        "      word_ctr+=1\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "len(word_dict)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "113654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1y0dRm-AI_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stop = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkjlCApaAO2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vectorizer = TfidfVectorizer(stop_words = stop)\n",
        "#tfidf_matrix = vectorizer.fit_transform(X)\n",
        "#tfidf_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwY9JXoOEAWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b0ae9791-41aa-4868-fd07-5a64433ef221"
      },
      "source": [
        "\"\"\"\n",
        "def objective_function_w(params):\n",
        "\n",
        "    max_depth, n_estimators = params\n",
        "    print('max_depth :{}'.format(max_depth))\n",
        "    print('n_estimators :{}'.format(n_estimators))\n",
        "    xgb_clf = xgb.XGBClassifier(max_depth = max_depth , \n",
        "                              n_estimators = n_estimators , \n",
        "                              random_state =7,\n",
        "                              n_jobs = -1)\n",
        "            \n",
        "    fitted_model = xgb_clf.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = xgb_clf.predict(x_val)\n",
        "        \n",
        "    metric = f1_score(y_true = y_val, y_pred = y_pred)\n",
        "            \n",
        "    if metric == None:\n",
        "      return 0\n",
        "    else:\n",
        "      return -metric \n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef objective_function_w(params):\\n\\n    max_depth, n_estimators = params\\n    print('max_depth :{}'.format(max_depth))\\n    print('n_estimators :{}'.format(n_estimators))\\n    xgb_clf = xgb.XGBClassifier(max_depth = max_depth , \\n                              n_estimators = n_estimators , \\n                              random_state =7,\\n                              n_jobs = -1)\\n            \\n    fitted_model = xgb_clf.fit(x_train, y_train)\\n\\n    y_pred = xgb_clf.predict(x_val)\\n        \\n    metric = f1_score(y_true = y_val, y_pred = y_pred)\\n            \\n    if metric == None:\\n      return 0\\n    else:\\n      return -metric \\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN4ea2VHNdSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#space = [(3, 15),(50, 100)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsxOMYdmKOVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start_time = time.time()\n",
        "#res = skopt.gp_minimize(objective_function_w, space , n_calls=51, n_random_starts=11 , verbose=True)\n",
        "#print('time taken to hyperopt : {}'.format(round(int(time.time() -start_time), 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bN53o7tKeIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = 64\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased' , max_len = max_seq_length)\n",
        "model = BertModel.from_pretrained('bert-large-uncased' , output_hidden_states=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdSeeqGnmCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0742fd0-9fdd-4daa-e5b9-48099b2cb734"
      },
      "source": [
        "embeddings_matrix =  np.zeros((X.shape[0] , 1024))\n",
        "embeddings_matrix.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TgM6VMynyvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4aa885b-fc3b-4584-b06c-c60d82a40857"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('CUDA available using GPU')\n",
        "else :\n",
        "   device = torch.device('cpu')\n",
        "   print('CUDA NOT available using CPU')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available using GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtLwA2TULeW2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "578eddc1-b3a4-406b-c2fc-829ae29fa5a7"
      },
      "source": [
        "model = model.to(device)\n",
        "print_every = 100\n",
        "record_ctr = 0\n",
        "start_time_loop = time.time()\n",
        "start_time = start_time_loop\n",
        "time_list = []\n",
        "for i in X.index:\n",
        "  sentence = X.loc[i]\n",
        "  input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)[:max_seq_length]).unsqueeze(0)\n",
        "  outputs = model(input_ids.to(device))\n",
        "  last_layer = outputs[2][12][0][0]\n",
        "  layer_11 = outputs[2][11][0][0]\n",
        "  layer_10 = outputs[2][10][0][0]\n",
        "  layer_9 = outputs[2][9][0][0]\n",
        "\n",
        "  final_embedding = last_layer + layer_11 + layer_10 + layer_9\n",
        "\n",
        "  embeddings_matrix[i]+=final_embedding.cpu().detach().numpy()\n",
        "\n",
        "  if record_ctr % print_every == 0 :\n",
        "    print('index {} / {} , {}'.format(i , X.shape[0] , time.time() - start_time))\n",
        "    time_list.append(time.time() - start_time)\n",
        "    start_time = time.time()\n",
        "\n",
        "  record_ctr+=1\n",
        "\n",
        "try:\n",
        "  np.save('embeddings_matrix' , arr = embeddings_matrix , allow_pickle=True)\n",
        "  print('Saved matrix locally')\n",
        "except:\n",
        "  print('ERROR saving embeddings')\n",
        "  print('time taken to generate embeddings : {}'.format(time.time() - start_time_loop))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index 0 / 7613 , 0.04597616195678711\n",
            "index 100 / 7613 , 3.8083250522613525\n",
            "index 200 / 7613 , 3.7330832481384277\n",
            "index 300 / 7613 , 3.7903568744659424\n",
            "index 400 / 7613 , 3.7696237564086914\n",
            "index 500 / 7613 , 3.919287919998169\n",
            "index 600 / 7613 , 3.809907913208008\n",
            "index 700 / 7613 , 3.767367124557495\n",
            "index 800 / 7613 , 3.8602089881896973\n",
            "index 900 / 7613 , 3.7861969470977783\n",
            "index 1000 / 7613 , 3.831881523132324\n",
            "index 1100 / 7613 , 3.7365567684173584\n",
            "index 1200 / 7613 , 3.7784335613250732\n",
            "index 1300 / 7613 , 3.950472116470337\n",
            "index 1400 / 7613 , 4.153333425521851\n",
            "index 1500 / 7613 , 3.807671070098877\n",
            "index 1600 / 7613 , 4.038038492202759\n",
            "index 1700 / 7613 , 3.7569336891174316\n",
            "index 1800 / 7613 , 3.8387670516967773\n",
            "index 1900 / 7613 , 3.7633538246154785\n",
            "index 2000 / 7613 , 3.83243989944458\n",
            "index 2100 / 7613 , 3.81644868850708\n",
            "index 2200 / 7613 , 3.9596896171569824\n",
            "index 2300 / 7613 , 3.7657554149627686\n",
            "index 2400 / 7613 , 3.714146375656128\n",
            "index 2500 / 7613 , 3.7513177394866943\n",
            "index 2600 / 7613 , 3.7280592918395996\n",
            "index 2700 / 7613 , 3.776343822479248\n",
            "index 2800 / 7613 , 3.836864471435547\n",
            "index 2900 / 7613 , 4.050313472747803\n",
            "index 3000 / 7613 , 3.922041893005371\n",
            "index 3100 / 7613 , 3.8938233852386475\n",
            "index 3200 / 7613 , 3.9609267711639404\n",
            "index 3300 / 7613 , 3.7907960414886475\n",
            "index 3400 / 7613 , 3.8121337890625\n",
            "index 3500 / 7613 , 3.6778087615966797\n",
            "index 3600 / 7613 , 3.8137900829315186\n",
            "index 3700 / 7613 , 3.742227792739868\n",
            "index 3800 / 7613 , 3.814166307449341\n",
            "index 3900 / 7613 , 3.7216849327087402\n",
            "index 4000 / 7613 , 3.7043650150299072\n",
            "index 4100 / 7613 , 3.8826305866241455\n",
            "index 4200 / 7613 , 3.720078706741333\n",
            "index 4300 / 7613 , 3.748769521713257\n",
            "index 4400 / 7613 , 3.925891637802124\n",
            "index 4500 / 7613 , 4.1158387660980225\n",
            "index 4600 / 7613 , 3.7704529762268066\n",
            "index 4700 / 7613 , 4.1155335903167725\n",
            "index 4800 / 7613 , 3.7085509300231934\n",
            "index 4900 / 7613 , 3.7617831230163574\n",
            "index 5000 / 7613 , 3.79502010345459\n",
            "index 5100 / 7613 , 3.7707338333129883\n",
            "index 5200 / 7613 , 3.8886539936065674\n",
            "index 5300 / 7613 , 3.800379753112793\n",
            "index 5400 / 7613 , 3.818220615386963\n",
            "index 5500 / 7613 , 3.819518804550171\n",
            "index 5600 / 7613 , 3.7999677658081055\n",
            "index 5700 / 7613 , 3.75357985496521\n",
            "index 5800 / 7613 , 3.736269235610962\n",
            "index 5900 / 7613 , 3.8424158096313477\n",
            "index 6000 / 7613 , 3.8121752738952637\n",
            "index 6100 / 7613 , 4.108695030212402\n",
            "index 6200 / 7613 , 3.685976982116699\n",
            "index 6300 / 7613 , 3.9918951988220215\n",
            "index 6400 / 7613 , 3.702641248703003\n",
            "index 6500 / 7613 , 3.742427349090576\n",
            "index 6600 / 7613 , 3.6869614124298096\n",
            "index 6700 / 7613 , 3.7533700466156006\n",
            "index 6800 / 7613 , 3.628540515899658\n",
            "index 6900 / 7613 , 3.7921698093414307\n",
            "index 7000 / 7613 , 3.6402530670166016\n",
            "index 7100 / 7613 , 3.6974658966064453\n",
            "index 7200 / 7613 , 3.73897123336792\n",
            "index 7300 / 7613 , 3.800765037536621\n",
            "index 7500 / 7613 , 3.7321269512176514\n",
            "index 7600 / 7613 , 3.7375905513763428\n",
            "Saved matrix locally\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WLClxRolVuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a9cd2388-2dc1-457a-d9c6-c10b364aa939"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(embeddings_matrix, Y, test_size=0.15, random_state=7)\n",
        "print('x_train :{}'.format(x_train.shape))\n",
        "print('y_train :{}'.format(y_train.shape))\n",
        "print('x_val :{}'.format(x_val.shape))\n",
        "print('y_val :{}'.format(y_val.shape))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train :(6471, 1024)\n",
            "y_train :(6471,)\n",
            "x_val :(1142, 1024)\n",
            "y_val :(1142,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2GsmwP_w0H6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "808666bc-de69-4e02-f9a9-6db93f24fdd7"
      },
      "source": [
        "final_embedding.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfhXkW82lh9E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "82845bf2-cc9d-4e58-ec02-e2a63723dee5"
      },
      "source": [
        "batch_size = 512\n",
        "#Convert input data to tensors\n",
        "x_train_data_tensor = torch.tensor(x_train)\n",
        "y_train_data_tensor = torch.tensor(y_train.values)\n",
        "print(x_train_data_tensor.shape)\n",
        "\n",
        "#Convert tensors to type Dataset\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train_data_tensor ,y_train_data_tensor)\n",
        "print(type(train_dataset))\n",
        "\n",
        "#Convert datsets to Dataloader for loading batches\n",
        "train_dataset = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "print(type(train_dataset))\n",
        "\n",
        "torch.save(train_dataset, 'train_dataset.dataloader')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6471, 1024])\n",
            "<class 'torch.utils.data.dataset.TensorDataset'>\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRQ2x3sbl4Z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "336517f5-bb72-4e3e-fd24-5c422dc1b3e4"
      },
      "source": [
        "#Convert input data to tensors\n",
        "x_val_data_tensor = torch.tensor(x_val)\n",
        "y_val_data_tensor = torch.tensor(y_val.values)\n",
        "print(x_val_data_tensor.shape)\n",
        "\n",
        "#Convert tensors to type Dataset\n",
        "val_dataset = torch.utils.data.TensorDataset(x_val_data_tensor ,y_val_data_tensor)\n",
        "print(type(val_dataset))\n",
        "\n",
        "#Convert datsets to Dataloader for loading batches\n",
        "val_dataset = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "type(val_dataset)\n",
        "\n",
        "torch.save(val_dataset, 'val_dataset.dataloader')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1142, 1024])\n",
            "<class 'torch.utils.data.dataset.TensorDataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUoW_O9VojE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_size = len(Y.unique())\n",
        "batch_size = batch_size\n",
        "drop_out_probability = 0.33\n",
        "input_size = 1024\n",
        "hidden_size = input_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0y6pUMJorTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERT_Classification(nn.Module):\n",
        "    def __init__(self , input_size , hidden_size , output_size):\n",
        "        super(BERT_Classification ,self).__init__()\n",
        "        \n",
        "        self.fc_input_size = input_size\n",
        "        self.fc_hidden_size = hidden_size\n",
        "        self.fc_output_size = output_size\n",
        "        \n",
        "        \n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.fc1 = nn.Linear(in_features = input_size , out_features = hidden_size)\n",
        "        self.fc2 = nn.Linear(in_features = input_size , out_features = hidden_size)\n",
        "        self.dropout = nn.Dropout(p = 0.33)\n",
        "        \n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.out = nn.Linear(in_features = hidden_size , out_features = output_size)\n",
        "        \n",
        "        \n",
        "    def forward(self,x):\n",
        "        \n",
        "        #Pass output of BERT through Fully connected layer\n",
        "        x = self.fc1(x)\n",
        "        x = torch.tanh(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = torch.tanh(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        #Output layer\n",
        "        x = self.out(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "bert_classification = BERT_Classification(input_size = input_size \n",
        "                            , hidden_size = input_size \n",
        "                            , output_size = output_size )\n",
        "\n",
        "bert_classification = bert_classification.double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u106hj3o65Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "4b1cd7cf-e6ac-4d71-f76a-2f7876fb9ede"
      },
      "source": [
        "epochs = 10\n",
        "loss_fn = F.cross_entropy\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer = torch.optim.Adam(bert_classification.parameters(), lr = learning_rate)\n",
        "print_every = 100\n",
        "bert_classification.to(device)\n",
        "\n",
        "\n",
        "# to track the average training loss per epoch as the model trains\n",
        "avg_train_losses = []\n",
        "# to track the average validation loss per epoch as the model trains\n",
        "avg_valid_losses = [] \n",
        "patience_ctr = 0\n",
        "patience = 5\n",
        "    \n",
        "for epoch in range(0,epochs):\n",
        "    \n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "\n",
        "    batch = 0\n",
        "    #loss = 0\n",
        "    start_time = time.time()\n",
        "    bert_classification.train()\n",
        "    for i in range(0,len(train_dataset)) :\n",
        "        x, y = next(iter(train_dataset))\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        y_pred = bert_classification(x)\n",
        "        \n",
        "        #y_pred = y_pred.unsqueeze(0)\n",
        "        loss = loss_fn(y_pred , y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        \n",
        "        if (batch % print_every == 0):\n",
        "            print('epoch : {} \\t batch number : {} \\t train loss : {}'.format(epoch, batch,loss.item()))\n",
        "            \n",
        "        batch +=1\n",
        "\n",
        "        #Calculate Validation loss\n",
        "    val_acc = 0\n",
        "    bert_classification.eval()\n",
        "    for j in val_dataset :\n",
        "        x_v, y_v = next(iter(val_dataset))\n",
        "        x_v = x_v.to(device)\n",
        "        y_v = y_v.to(device)\n",
        "        \n",
        "        y_pred = bert_classification(x_v)\n",
        "        loss = loss_fn(y_pred , y_v)\n",
        "        \n",
        "        valid_losses.append(loss.item())\n",
        "    \n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = np.average(train_losses)\n",
        "    valid_loss = np.average(valid_losses)\n",
        "    avg_train_losses.append(train_loss)\n",
        "    avg_valid_losses.append(valid_loss)\n",
        "\n",
        "    #Early stopping\n",
        "    if valid_loss > train_loss:\n",
        "        patience_ctr +=1\n",
        "        print('patience_ctr : {}'.format(patience_ctr))\n",
        "        if patience_ctr >= patience:\n",
        "            print('early stoppping since valid_loss > train_loss')\n",
        "            break\n",
        "    else :\n",
        "        patience_ctr = 0\n",
        "    \n",
        "    epoch_len = len(str(epochs))\n",
        "    print('epoch : {}\\t train_loss :{}\\t validation loss : {}\\n'.format(epoch , train_loss , valid_loss))\n",
        "    \n",
        "            \n",
        "    print('epoch : {} \\t train loss : {} \\t time required : {}'.format(epoch, loss.item(),(time.time() - start_time)))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 \t batch number : 0 \t train loss : 0.7218916154026157\n",
            "epoch : 0\t train_loss :1.7148826930910739\t validation loss : 0.7505196442914227\n",
            "\n",
            "epoch : 0 \t train loss : 0.7543187194902152 \t time required : 0.14241242408752441\n",
            "epoch : 1 \t batch number : 0 \t train loss : 0.7489626884167778\n",
            "epoch : 1\t train_loss :0.7421361936357826\t validation loss : 0.6723375562515951\n",
            "\n",
            "epoch : 1 \t train loss : 0.6775516088679728 \t time required : 0.13022685050964355\n",
            "epoch : 2 \t batch number : 0 \t train loss : 0.6787169280191679\n",
            "epoch : 2\t train_loss :0.6737358352438438\t validation loss : 0.6198444259243683\n",
            "\n",
            "epoch : 2 \t train loss : 0.620100019866864 \t time required : 0.1421968936920166\n",
            "epoch : 3 \t batch number : 0 \t train loss : 0.6306895154327397\n",
            "epoch : 3\t train_loss :0.558231393459889\t validation loss : 0.5216853116171739\n",
            "\n",
            "epoch : 3 \t train loss : 0.5279248726900445 \t time required : 0.14907407760620117\n",
            "epoch : 4 \t batch number : 0 \t train loss : 0.49183796293813503\n",
            "patience_ctr : 1\n",
            "epoch : 4\t train_loss :0.4768370880063592\t validation loss : 0.49131724889166484\n",
            "\n",
            "epoch : 4 \t train loss : 0.5106871088924682 \t time required : 0.1274557113647461\n",
            "epoch : 5 \t batch number : 0 \t train loss : 0.4666275648984415\n",
            "patience_ctr : 2\n",
            "epoch : 5\t train_loss :0.4487896387559783\t validation loss : 0.4575708305303811\n",
            "\n",
            "epoch : 5 \t train loss : 0.4427800780772643 \t time required : 0.13879799842834473\n",
            "epoch : 6 \t batch number : 0 \t train loss : 0.4550528587998408\n",
            "epoch : 6\t train_loss :0.448927342746528\t validation loss : 0.4401251174880001\n",
            "\n",
            "epoch : 6 \t train loss : 0.4509951529907081 \t time required : 0.13062644004821777\n",
            "epoch : 7 \t batch number : 0 \t train loss : 0.4341777085120273\n",
            "patience_ctr : 1\n",
            "epoch : 7\t train_loss :0.44280484742252046\t validation loss : 0.4435748619488858\n",
            "\n",
            "epoch : 7 \t train loss : 0.46204668969726004 \t time required : 0.26842546463012695\n",
            "epoch : 8 \t batch number : 0 \t train loss : 0.4400712118417314\n",
            "patience_ctr : 2\n",
            "epoch : 8\t train_loss :0.4263668918094697\t validation loss : 0.4493203247692689\n",
            "\n",
            "epoch : 8 \t train loss : 0.4400421169469117 \t time required : 0.13677620887756348\n",
            "epoch : 9 \t batch number : 0 \t train loss : 0.3962981384863478\n",
            "patience_ctr : 3\n",
            "epoch : 9\t train_loss :0.42465761238211336\t validation loss : 0.4514202666839014\n",
            "\n",
            "epoch : 9 \t train loss : 0.44294956370561556 \t time required : 0.13005948066711426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2COdf-mtso10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90999612-f15a-4692-c08d-07adf4e053fc"
      },
      "source": [
        "st_time = time.time()\n",
        "ctr = 0\n",
        "print_every = 5\n",
        "bert_classification = bert_classification.double()\n",
        "bert_classification = bert_classification.to(device)\n",
        "bert_classification = bert_classification.eval()\n",
        "for j in val_dataset :\n",
        "    x_v, y_v = next(iter(val_dataset))\n",
        "    x_v = x_v.to(device)\n",
        "    #y_v = y_v.to(device)\n",
        "   \n",
        "    op = bert_classification(x_v)\n",
        "    op = torch.argmax(torch.sigmoid(op), dim = 1)\n",
        "    if ctr == 0:\n",
        "        y_pred = op\n",
        "        y_actual = y_v\n",
        "    else:\n",
        "        y_pred = torch.cat((y_pred , op))\n",
        "        y_actual = torch.cat((y_actual , y_v))\n",
        "   \n",
        "    ctr += 1\n",
        "   \n",
        "    if ctr % print_every == 0:\n",
        "        print(ctr)\n",
        "print('time taken for prediction :{} seconds'.format(time.time() - st_time ))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time taken for prediction :0.030162572860717773 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh_ppPmos6IA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "56d68330-ec07-43d8-e66a-e8eb8cc01c13"
      },
      "source": [
        "def my_classification_report(y_actual , y_predicted):\n",
        "   \n",
        "    print(classification_report(y_actual, y_pred))\n",
        "    acc = accuracy_score(y_actual , y_predicted)\n",
        "    print('accuracy : {}'.format(acc))\n",
        "   \n",
        "    conf_mat=confusion_matrix(y_actual, y_pred)\n",
        "    print(conf_mat)\n",
        "    #plt.figure(figsize=(20,20))\n",
        "    ax = plt.subplot()\n",
        "    sns.heatmap(conf_mat, annot=True, ax = ax); #annot=True to annotate cells\n",
        "\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels')\n",
        "    ax.set_ylabel('True labels')\n",
        "    ax.set_title('Confusion Matrix')\n",
        "    #ax.xaxis.set_ticklabels(list(label_encoder.classes_))\n",
        "    #ax.yaxis.set_ticklabels(list(label_encoder.classes_))\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    #plt.savefig('conf_matrix.png')\n",
        "    plt.show()\n",
        "\n",
        "y_actual = y_actual.cpu().detach().numpy()\n",
        "y_pred = y_pred.cpu().detach().numpy()\n",
        "my_classification_report(y_actual = y_actual , y_predicted = y_pred)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.83       854\n",
            "           1       0.83      0.71      0.76       682\n",
            "\n",
            "    accuracy                           0.81      1536\n",
            "   macro avg       0.81      0.80      0.80      1536\n",
            "weighted avg       0.81      0.81      0.80      1536\n",
            "\n",
            "accuracy : 0.8053385416666666\n",
            "[[754 100]\n",
            " [199 483]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAETCAYAAADwNyfUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktfHoTzNy3Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}